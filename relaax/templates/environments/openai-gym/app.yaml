---

environment:
  run: python3 environment/training.py
  name: Pendulum-v0
  shape: [3]
  max_episodes: 10000
  infinite_run: False

relaax-parameter-server:
  --bind: localhost:7000
  --metrics-dir: logs/metrics
  --checkpoint-dir: logs/checkpoints
  --log-level: INFO

relaax-rlx-server:
  --bind: localhost:7001
  --log-level: INFO

algorithm:
  name: da3c

  input:
    shape: [3]
    history: 1
    use_convolutions: false

  output:
    continuous: true
    action_size: 1                # action size for the given environment

  batch_size: 5                   # local loop size for one episode

  use_lstm: false                 # to use LSTM instead of FF, set to the True
  max_global_step: 2e7            # amount of maximum global steps to pass through the training

  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # rewards discount factor
  use_gae: false                  # switcher for generalized advantage estimation
  gae_lambda: 1.00                # lambda for generalized advantage estimation

  initial_learning_rate: 1e-2
  optimizer: Adam

  RMSProp:
    decay: 0.99
    epsilon: 0.1
