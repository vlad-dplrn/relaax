algorithm:
  name: da3c

  input:
    shape: [42, 42]
    history: 1
    use_convolutions: true

  output:
    continuous: false
    action_size: 4                # action size for the given environment

  hidden_sizes: [256]
  batch_size: 20                   # local loop size for one episode

  use_icm: false
  use_lstm: true                  # to use LSTM instead of FF, set to the True
  max_global_step: 1e8            # amount of maximum global steps to pass through the training

  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # rewards discount factor
  gae-lambda: 0.97                # lambda for generalized advantage estimation

  initial_learning_rate: 1e-4
  gradients_norm_clipping: 40.    # gradients clipping global norm
  optimizer: Adam

  RMSProp:
    decay: 0.99
    epsilon: 0.1

  ICM:
    alpha: 0.1
    beta: 0.2
