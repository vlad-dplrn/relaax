#!/usr/bin/env python

from __future__ import print_function

import logging
import math
import numpy as np
import random
import six

from relaax.client import rlx_client_config
from relaax.client import rlx_client


class Numerator(object):
    LOW = 0
    HIGH = 84
    MID = math.floor((LOW + HIGH) / 2)
    ACTION_STEP = 3
    ZONE = 5
    N_STEPS = 200
    MAX_SPEED = 3

    def __init__(self):
        self._level = self.MID
        self._step = 0
        self._speed = 0
        self.reset()

    def act(self, action):
        assert action in range(2)
        # action = random.randint(0, 1)
        if action == 1:
            self._level -= self.ACTION_STEP

        reward = 0
        if abs(self._level - self.MID) < self.ZONE:
            reward = 1

        self._next_step()
        reset = False
        if self._step >= self.N_STEPS:
            reset = True
        if self._level < self.LOW or self.HIGH <= self._level:
            reset = True
        if abs(self._level - self.MID) > self.ZONE:
            reset = True

        return reward, reset

    def reset(self):
        self._level = self.MID
        self._step = 0
        self._speed = 0
        self._next_step()

    def state(self):
        picture = np.zeros((84, 84), dtype=np.float32)
        for i in six.moves.xrange(self._level):
            for j in six.moves.xrange(picture.shape[1]):
                picture[i, j] = 1
        return picture


    def _next_step(self):
        low = -1
        high = 1
        if self._speed == 0:
            low = 0
        if self._speed == self.MAX_SPEED:
            high = 0
        self._speed += random.randint(low, high)

        self._level += self._speed

        self._step += 1


def run():
    rlx_server_url = rlx_client_config.options.get('environment/rlx_server')
    rom = rlx_client_config.options.get('environment/rom')
    display = False
    seed = None

    n_game = 0
    env = Numerator()

    agent = rlx_client.RlxClient(rlx_server_url)
    assert agent is not None
    try:
        agent.connect()
        agent.init()
        episode_reward = 0
        reward = None
        while True:
            try:
                action = agent.update(reward=reward, state=env.state(), terminal=False)
                # print('ACTION', repr(action))
                reward, reset = env.act(action['data'])
                if reward is not None:
                    episode_reward += reward
                if reset:
                    agent.update(reward=reward, state=None, terminal=True)
                    reward = None
                    n_game += 1
                    agent.metrics.scalar('game_score', episode_reward)
                    print('game_score', episode_reward)
                    env.reset()
                    episode_reward = 0
            except rlx_client.RlxClientException as e:
                print("agent error: ", e)
                env.reset()
                agent.connect(retry=10)
                agent.init()
                episode_reward = 0
                reward = None

        agent.reset()

    finally:
        agent.disconnect()


run()
